{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### assignment 2\n",
    "\n",
    "#load data\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib\n",
    "import random\n",
    "#将数据划分成训练集和测试集,存储成train.txt,test.txt(data.txt包括5个字段，图片路径 人 朝向 情绪 眼镜)\n",
    "#每张图片有0.1的几率进入测试集\n",
    "\n",
    "root = os.getcwd()\n",
    "file_path = root + '/emotion/faces_4/'\n",
    "\n",
    "emotion_dict = {'angry':0,'happy':1,'neutral':2,'sad':3}\n",
    "emotion_list = ['angry','happpy','neutral','sad']\n",
    "\n",
    "with open(\"emotion_train.txt\",'w') as train_fw:\n",
    "    with open(\"emotion_test.txt\",'w') as test_fw:\n",
    "        for root,dirs,files in os.walk(file_path):\n",
    "            for tmp in dirs:\n",
    "                tmp_path = file_path + tmp\n",
    "                for x,y,images in os.walk(tmp_path):\n",
    "                    for image in images:     \n",
    "                        image_name = image.split(\"_\")\n",
    "                        name = image_name[0]\n",
    "                        direction = image_name[1]\n",
    "                        emotion = image_name[2]\n",
    "                        glass = image_name[3]\n",
    "                        random_num = random.uniform(0.,1.)\n",
    "                        if random_num <0.1:\n",
    "                            test_fw.write(tmp_path+\"/\"+image+\" \"+name+\" \"+direction+\" \"+str(emotion_dict[emotion])+\" \"+glass+\"\\n\")\n",
    "                        else:\n",
    "                            train_fw.write(tmp_path+\"/\"+image+\" \"+name+\" \"+direction+\" \"+str(emotion_dict[emotion])+\" \"+glass+\"\\n\")\n",
    "                \n",
    "                \n",
    "# training_set = (\n",
    "#     torchvision.datasets.mnist.read_image_file(os.path.join('/home/kuangjun/course/机器学习/emotion', 'train-images-idx3-ubyte/data')),\n",
    "#     torchvision.datasets.mnist.read_label_file(os.path.join('/home/kuangjun/course/机器学习/mnist', 'train-labels-idx1-ubyte/data'))\n",
    "# )\n",
    "# testing_set = (\n",
    "#     torchvision.datasets.mnist.read_image_file(os.path.join('/home/kuangjun/course/机器学习/mnist','t10k-images-idx3-ubyte/data')),\n",
    "#     torchvision.datasets.mnist.read_label_file(os.path.join('/home/kuangjun/course/机器学习/mnist','t10k-labels-idx1-ubyte/data'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "#hyper parameters\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001  #学习率 \n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('L')\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0],int(words[3])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "root = os.getcwd()\n",
    "train_data=MyDataset(txt=root+'/emotion_train.txt', transform=transforms.ToTensor())\n",
    "test_data=MyDataset(txt=root+'/emotion_test.txt', transform=transforms.ToTensor())\n",
    "#一个batch BATCH_SIZE个sample , 1 channel, 28*28 (BATCH_SIZE,1,28,28)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=2048, out_features=20, bias=True)\n",
      ")\n",
      "/home/kuangjun/course/机器学习/emotion/faces_4/megak\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.060890, Acc: 0.237113\n",
      "Test Loss: 0.069765, Acc: 0.309524\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.045963, Acc: 0.245704\n",
      "Test Loss: 0.071238, Acc: 0.333333\n",
      "epoch 3\n",
      "Train Loss: 0.046251, Acc: 0.262887\n",
      "Test Loss: 0.068679, Acc: 0.166667\n",
      "epoch 4\n",
      "Train Loss: 0.045662, Acc: 0.238832\n",
      "Test Loss: 0.067691, Acc: 0.333333\n",
      "epoch 5\n",
      "Train Loss: 0.045607, Acc: 0.261168\n",
      "Test Loss: 0.066064, Acc: 0.238095\n",
      "epoch 6\n",
      "Train Loss: 0.045787, Acc: 0.242268\n",
      "Test Loss: 0.066520, Acc: 0.357143\n",
      "epoch 7\n",
      "Train Loss: 0.045973, Acc: 0.225086\n",
      "Test Loss: 0.067255, Acc: 0.238095\n",
      "epoch 8\n",
      "Train Loss: 0.046181, Acc: 0.223368\n",
      "Test Loss: 0.066656, Acc: 0.166667\n",
      "epoch 9\n",
      "Train Loss: 0.045472, Acc: 0.266323\n",
      "Test Loss: 0.065987, Acc: 0.166667\n",
      "epoch 10\n",
      "Train Loss: 0.045276, Acc: 0.269759\n",
      "Test Loss: 0.065662, Acc: 0.285714\n",
      "epoch 11\n",
      "Train Loss: 0.045174, Acc: 0.307560\n",
      "Test Loss: 0.069083, Acc: 0.166667\n",
      "epoch 12\n",
      "Train Loss: 0.044986, Acc: 0.262887\n",
      "Test Loss: 0.064802, Acc: 0.285714\n",
      "epoch 13\n",
      "Train Loss: 0.045348, Acc: 0.266323\n",
      "Test Loss: 0.066689, Acc: 0.142857\n",
      "epoch 14\n",
      "Train Loss: 0.045208, Acc: 0.262887\n",
      "Test Loss: 0.067137, Acc: 0.190476\n",
      "epoch 15\n",
      "Train Loss: 0.045317, Acc: 0.286942\n",
      "Test Loss: 0.065896, Acc: 0.309524\n",
      "epoch 16\n",
      "Train Loss: 0.045047, Acc: 0.281787\n",
      "Test Loss: 0.067694, Acc: 0.261905\n",
      "epoch 17\n",
      "Train Loss: 0.044901, Acc: 0.300687\n",
      "Test Loss: 0.065836, Acc: 0.333333\n",
      "epoch 18\n",
      "Train Loss: 0.044877, Acc: 0.274914\n",
      "Test Loss: 0.065556, Acc: 0.309524\n",
      "epoch 19\n",
      "Train Loss: 0.045263, Acc: 0.292096\n",
      "Test Loss: 0.067506, Acc: 0.142857\n",
      "epoch 20\n",
      "Train Loss: 0.044755, Acc: 0.310997\n",
      "Test Loss: 0.065682, Acc: 0.285714\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "#构建网络，进行训练\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(  # input shape (1, 32, 32)\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=16,    # n_filters\n",
    "                kernel_size=3,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=1,      \n",
    "            ),      # output shape (16, 32, 32)\n",
    "            torch.nn.ReLU(),    # activation\n",
    "            torch.nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 16, 16)\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(  # input shape (16, 16, 16)\n",
    "            torch.nn.Conv2d(16, 32, 3, 1, 1),  # output shape (32, 16, 16)\n",
    "            torch.nn.ReLU(),  # activation\n",
    "            torch.nn.MaxPool2d(2),  # output shape (32, 8, 8)\n",
    "        )\n",
    "        self.out = torch.nn.Linear(32 * 8 * 8, 20)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        #将1*32*32补成1*32*32\n",
    "        x = F.pad(x,(0,0,1,1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    \n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(x)\n",
    "for epoch in range(EPOCH):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    # training-----------------------------\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for batch_x,batch_y in train_loader:\n",
    "    \n",
    "        batch_y = torch.tensor(list(batch_y))\n",
    "       \n",
    "        batch_x, batch_y = Variable(batch_x), Variable(batch_y)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        train_loss += loss.data[0]\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == batch_y).sum()\n",
    "        train_acc += train_correct.data[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = train_acc.float()\n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss / (len(\n",
    "        train_data)), train_acc / (len(train_data))))\n",
    "    \n",
    "\n",
    "    # evaluation--------------------------------\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for batch_x ,batch_y in test_loader:\n",
    "        batch_x, batch_y = Variable(batch_x, volatile=True), Variable(batch_y, volatile=True)\n",
    "        out = model(batch_x)\n",
    "        loss = loss_func(out, batch_y)\n",
    "        eval_loss += loss.data[0]\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        num_correct = (pred == batch_y).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    eval_acc = eval_acc.float()\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_data)), eval_acc / (len(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess these emotion above are:\n",
      "\n",
      "happpy,angry,angry,happpy,angry\n",
      "angry,\n",
      "The real answer is :\n",
      "happpy,happpy,happpy,sad,sad\n",
      "sad,"
     ]
    }
   ],
   "source": [
    "#加载测试集的前10张图片查看运行效果\n",
    "%matplotlib inline\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('L')\n",
    "class MyVisualDataset(Dataset):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.strip('\\n')\n",
    "            imgs.append(line)\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "from matplotlib import pyplot # pyplot 用于显示图片\n",
    "from matplotlib import image # image 用于读取图片\n",
    "from PIL import Image\n",
    "\n",
    "root = os.getcwd()\n",
    "real_answer = []\n",
    "with open('visual_test.txt','w') as fw:\n",
    "    with open(\"emotion_test.txt\",'r') as fr:\n",
    "        i = 0\n",
    "        j = 5\n",
    "        for line in fr:\n",
    "            if(j%7):\n",
    "                j+=1\n",
    "                continue\n",
    "            j+=1\n",
    "            path = line.split()[0]\n",
    "            emotion = line.split()[3]\n",
    "            pic = Image.open(path)\n",
    "            real_answer.append(emotion_list[int(emotion)])\n",
    "            pyplot.subplot(2,5,i+1)\n",
    "            pyplot.axis('off')\n",
    "            pyplot.imshow(pic)\n",
    "            i+=1 \n",
    "            fw.write(path+'\\n')\n",
    "            if(i == 10):\n",
    "                break\n",
    "            \n",
    "pyplot.show()\n",
    "visual_data=MyVisualDataset(txt='visual_test.txt', transform=transforms.ToTensor())\n",
    "visual_loader = DataLoader(dataset=visual_data, batch_size=1)\n",
    "\n",
    "print(\"I guess these emotion above are:\")\n",
    "print(\"\")\n",
    "for index,x in enumerate(visual_loader):\n",
    "    x = Variable(x)\n",
    "    out = model(x)\n",
    "    pred = torch.max(out, 1)[1]\n",
    "    if((index+1)%5 !=0):\n",
    "        print(emotion_list[pred.data.numpy()[0]],end=',')\n",
    "    else:\n",
    "        print(emotion_list[pred.data.numpy()[0]])\n",
    "\n",
    "print()\n",
    "print(\"The real answer is :\")\n",
    "i = 0\n",
    "for emotion in real_answer:\n",
    "    if((i+1)%5 !=0):\n",
    "        print(emotion,end=',')\n",
    "    else:\n",
    "        print(emotion)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
